{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge: Spiral Data Classification\n",
    "\n",
    "Now that you completed Challenge 2, you know you can use the Tensorflow Playground to experiment the hyperparameters of your deep learning model. If you are brave enough to take on this challenge, we present you the spiral data generated by codes and you will replicate your model built visually in the Tensorflow Playground with Python codes.\n",
    "\n",
    "Below are the codes to generate the spiral dataset. Read the remarks and execute the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ruoxi\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from math import hypot, cos, sin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "A function to generate X/Y data points that will form a spiral.\n",
    "\"\"\"\n",
    "def spiral(radius, step, resolution=.1, angle=0.0, start=0.0):\n",
    "    dist = start\n",
    "    coords=[]\n",
    "    while dist*hypot(cos(angle),sin(angle))<radius:\n",
    "        cord=[]\n",
    "        cord.append(dist*cos(angle))\n",
    "        cord.append(dist*sin(angle))\n",
    "        coords.append(cord)\n",
    "        dist+=step\n",
    "        angle+=resolution\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate two sets of spiral data points with opposite angles\n",
    "data_1 = np.array(spiral(1000, 5, angle=0))\n",
    "data_2 = np.array(spiral(1000, 5, angle=180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the two datasets to visualize the spirals\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a, b = data_1.T\n",
    "plt.scatter(a, b, s=5)\n",
    "\n",
    "aa, bb = data_2.T\n",
    "plt.scatter(aa, bb, s=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASS\n",
       "0    200\n",
       "1    200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two spiral datasets into one\n",
    "\n",
    "df1 = pd.DataFrame(data=data_1, columns=[\"X\", \"Y\"])\n",
    "df1[\"CLASS\"] = 0\n",
    "\n",
    "df2 = pd.DataFrame(data=data_2, columns=[\"X\", \"Y\"])\n",
    "df2[\"CLASS\"] = 1\n",
    "\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "df['CLASS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, build a neural network with Tensorflow to classify `df`. See how low data loss and how high accuracy can you achieve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.62.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ruoxi\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
      "WARNING:tensorflow:From c:\\Users\\ruoxi\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "!pip install tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the feature engineering on X and Y\n",
    "import numpy as np\n",
    "\n",
    "df['sin_X'] = np.sin(df['X'])\n",
    "df['sin_Y'] = np.sin(df['Y'])\n",
    "df['XY'] = df['X']*df['Y']\n",
    "df['X2'] = df['X']*df['X']\n",
    "df['Y2'] = df['Y']*df['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>sin_X</th>\n",
       "      <th>sin_Y</th>\n",
       "      <th>XY</th>\n",
       "      <th>X2</th>\n",
       "      <th>Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.975021</td>\n",
       "      <td>0.499167</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.965710</td>\n",
       "      <td>0.478694</td>\n",
       "      <td>2.483367</td>\n",
       "      <td>24.750832</td>\n",
       "      <td>0.249168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.800666</td>\n",
       "      <td>1.986693</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.367099</td>\n",
       "      <td>0.914754</td>\n",
       "      <td>19.470917</td>\n",
       "      <td>96.053050</td>\n",
       "      <td>3.946950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.330047</td>\n",
       "      <td>4.432803</td>\n",
       "      <td>0</td>\n",
       "      <td>0.981456</td>\n",
       "      <td>-0.961170</td>\n",
       "      <td>63.522278</td>\n",
       "      <td>205.350257</td>\n",
       "      <td>19.649743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.421220</td>\n",
       "      <td>7.788367</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.415358</td>\n",
       "      <td>0.997848</td>\n",
       "      <td>143.471218</td>\n",
       "      <td>339.341342</td>\n",
       "      <td>60.658658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           X         Y  CLASS     sin_X     sin_Y          XY          X2  \\\n",
       "0   0.000000  0.000000      0  0.000000  0.000000    0.000000    0.000000   \n",
       "1   4.975021  0.499167      0 -0.965710  0.478694    2.483367   24.750832   \n",
       "2   9.800666  1.986693      0 -0.367099  0.914754   19.470917   96.053050   \n",
       "3  14.330047  4.432803      0  0.981456 -0.961170   63.522278  205.350257   \n",
       "4  18.421220  7.788367      0 -0.415358  0.997848  143.471218  339.341342   \n",
       "\n",
       "          Y2  \n",
       "0   0.000000  \n",
       "1   0.249168  \n",
       "2   3.946950  \n",
       "3  19.649743  \n",
       "4  60.658658  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['X', 'Y', 'sin_X', 'sin_Y', 'XY', 'X2', 'Y2']], df['CLASS'], test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled =scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=0.1>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create an instance of the Adam optimizer with the default learning rate\n",
    "adam_optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Manually set the learning rate\n",
    "new_learning_rate = 0.1\n",
    "adam_optimizer.learning_rate.assign(new_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "8/8 [==============================] - 2s 4ms/step - loss: 1.4507 - accuracy: 0.5437\n",
      "Epoch 2/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.4296 - accuracy: 0.5500\n",
      "Epoch 3/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.4091 - accuracy: 0.5375\n",
      "Epoch 4/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.3888 - accuracy: 0.5437\n",
      "Epoch 5/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.3686 - accuracy: 0.5437\n",
      "Epoch 6/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3489 - accuracy: 0.5406\n",
      "Epoch 7/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.3293 - accuracy: 0.5406\n",
      "Epoch 8/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.3101 - accuracy: 0.5469\n",
      "Epoch 9/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.2912 - accuracy: 0.5281\n",
      "Epoch 10/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2724 - accuracy: 0.5375\n",
      "Epoch 11/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.2540 - accuracy: 0.5344\n",
      "Epoch 12/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2358 - accuracy: 0.5250\n",
      "Epoch 13/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.2178 - accuracy: 0.5188\n",
      "Epoch 14/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1.2002 - accuracy: 0.5344\n",
      "Epoch 15/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1830 - accuracy: 0.5188\n",
      "Epoch 16/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1660 - accuracy: 0.5281\n",
      "Epoch 17/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1494 - accuracy: 0.5281\n",
      "Epoch 18/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1333 - accuracy: 0.5312\n",
      "Epoch 19/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.1175 - accuracy: 0.5281\n",
      "Epoch 20/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.1020 - accuracy: 0.5250\n",
      "Epoch 21/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.0868 - accuracy: 0.5281\n",
      "Epoch 22/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.0720 - accuracy: 0.5219\n",
      "Epoch 23/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.0575 - accuracy: 0.5156\n",
      "Epoch 24/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.0434 - accuracy: 0.5281\n",
      "Epoch 25/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.0294 - accuracy: 0.5312\n",
      "Epoch 26/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1.0157 - accuracy: 0.5437\n",
      "Epoch 27/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.0023 - accuracy: 0.5406\n",
      "Epoch 28/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9891 - accuracy: 0.5375\n",
      "Epoch 29/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.9761 - accuracy: 0.5281\n",
      "Epoch 30/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.9634 - accuracy: 0.5406\n",
      "Epoch 31/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9507 - accuracy: 0.5437\n",
      "Epoch 32/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.9384 - accuracy: 0.5219\n",
      "Epoch 33/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.9263 - accuracy: 0.5375\n",
      "Epoch 34/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.9147 - accuracy: 0.5437\n",
      "Epoch 35/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.9034 - accuracy: 0.5562\n",
      "Epoch 36/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.8922 - accuracy: 0.5562\n",
      "Epoch 37/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.8815 - accuracy: 0.5375\n",
      "Epoch 38/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8712 - accuracy: 0.5562\n",
      "Epoch 39/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8613 - accuracy: 0.5437\n",
      "Epoch 40/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8515 - accuracy: 0.5437\n",
      "Epoch 41/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.8421 - accuracy: 0.5594\n",
      "Epoch 42/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.8329 - accuracy: 0.5625\n",
      "Epoch 43/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.8241 - accuracy: 0.5344\n",
      "Epoch 44/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.8156 - accuracy: 0.5031\n",
      "Epoch 45/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.8074 - accuracy: 0.5031\n",
      "Epoch 46/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7996 - accuracy: 0.5031\n",
      "Epoch 47/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7918 - accuracy: 0.5031\n",
      "Epoch 48/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7844 - accuracy: 0.5031\n",
      "Epoch 49/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7771 - accuracy: 0.5031\n",
      "Epoch 50/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7702 - accuracy: 0.5031\n",
      "Epoch 51/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7634 - accuracy: 0.5031\n",
      "Epoch 52/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7567 - accuracy: 0.5031\n",
      "Epoch 53/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7504 - accuracy: 0.5031\n",
      "Epoch 54/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.5031\n",
      "Epoch 55/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7384 - accuracy: 0.5031\n",
      "Epoch 56/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7330 - accuracy: 0.5031\n",
      "Epoch 57/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7278 - accuracy: 0.5031\n",
      "Epoch 58/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7231 - accuracy: 0.5031\n",
      "Epoch 59/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7191 - accuracy: 0.5031\n",
      "Epoch 60/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7150 - accuracy: 0.5031\n",
      "Epoch 61/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7113 - accuracy: 0.5031\n",
      "Epoch 62/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.7085 - accuracy: 0.5031\n",
      "Epoch 63/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.7059 - accuracy: 0.5031\n",
      "Epoch 64/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7040 - accuracy: 0.5031\n",
      "Epoch 65/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7020 - accuracy: 0.5031\n",
      "Epoch 66/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7002 - accuracy: 0.5031\n",
      "Epoch 67/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6985 - accuracy: 0.5031\n",
      "Epoch 68/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6970 - accuracy: 0.5031\n",
      "Epoch 69/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6961 - accuracy: 0.5031\n",
      "Epoch 70/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6953 - accuracy: 0.5031\n",
      "Epoch 71/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6947 - accuracy: 0.5031\n",
      "Epoch 72/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6942 - accuracy: 0.5031\n",
      "Epoch 73/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.5031\n",
      "Epoch 74/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.5031\n",
      "Epoch 75/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5031\n",
      "Epoch 76/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 77/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 78/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 79/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 80/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 81/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 82/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 83/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 84/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 85/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 86/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 87/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 88/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 89/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 90/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 91/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 92/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 93/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 94/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 95/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 96/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 97/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 98/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 99/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 100/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 101/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 102/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 103/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 104/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 105/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 106/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 107/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 108/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 109/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 110/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 111/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 112/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 113/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 114/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 115/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 116/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 117/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 118/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 119/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 120/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 121/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 122/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5031\n",
      "Epoch 123/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 124/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 125/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 126/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 127/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 128/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 129/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 130/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 131/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 132/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 133/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 134/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 135/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 136/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 137/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 138/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 139/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 140/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 141/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 142/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 143/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 144/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 145/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 146/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 147/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 148/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 149/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 150/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 151/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 152/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 153/300\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 154/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 155/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 156/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 157/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 158/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 159/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 160/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 161/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 162/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 163/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 164/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 165/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 166/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 167/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 168/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 169/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 170/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 171/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 172/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 173/300\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 174/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 175/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 176/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 177/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 178/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 179/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 180/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 181/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 182/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 183/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 184/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 185/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 186/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 187/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 188/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 189/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 190/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 191/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 192/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 193/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 194/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 195/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 196/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 197/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 198/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 199/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 200/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 201/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 202/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 203/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 204/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 205/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 206/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.5031\n",
      "Epoch 207/300\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 208/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 209/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 210/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 211/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 212/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 213/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 214/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 215/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 216/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 217/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 218/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 219/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 220/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 221/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 222/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 223/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 224/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 225/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 226/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 227/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 228/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 229/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 230/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 231/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 232/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 233/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 234/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 235/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 236/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 237/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 238/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 239/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 240/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 241/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 242/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 243/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 244/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5031\n",
      "Epoch 245/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 246/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 247/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 248/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 249/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 250/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 251/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 252/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 253/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 254/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 255/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 256/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 257/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5031\n",
      "Epoch 258/300\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 259/300\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 260/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 261/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 262/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 263/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 264/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 265/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 266/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 267/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 268/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 269/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 270/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.5031\n",
      "Epoch 271/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 272/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 273/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 274/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 275/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 276/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 277/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 278/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 279/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 280/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 281/300\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 282/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 283/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 284/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.5031\n",
      "Epoch 285/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 286/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 287/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 288/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 289/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 290/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 291/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 292/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 293/300\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 294/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 295/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 296/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 297/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 298/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 299/300\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.5031\n",
      "Epoch 300/300\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.5031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x208e4258990>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model with L1 regularization in the Dense layers\n",
    "model = Sequential([\n",
    "    Dense(10, activation='relu', input_shape=(X_train_scaled.shape[1],), kernel_regularizer=regularizers.l1(0.01)),\n",
    "    Dense(10, activation='relu', kernel_regularizer=regularizers.l1(0.01)),\n",
    "    Dense(10, activation='relu', kernel_regularizer=regularizers.l1(0.01)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train_scaled, y_train, epochs=300, batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6936 - accuracy: 0.4875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6936397552490234, 0.48750001192092896]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(\n",
    "  X_test_scaled,\n",
    "  y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
