{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge: Spiral Data Classification\n",
    "\n",
    "Now that you completed Challenge 2, you know you can use the Tensorflow Playground to experiment the hyperparameters of your deep learning model. If you are brave enough to take on this challenge, we present you the spiral data generated by codes and you will replicate your model built visually in the Tensorflow Playground with Python codes.\n",
    "\n",
    "Below are the codes to generate the spiral dataset. Read the remarks and execute the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import hypot, cos, sin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "A function to generate X/Y data points that will form a spiral.\n",
    "\"\"\"\n",
    "def spiral(radius, step, resolution=.1, angle=0.0, start=0.0):\n",
    "    dist = start\n",
    "    coords=[]\n",
    "    while dist*hypot(cos(angle),sin(angle))<radius:\n",
    "        cord=[]\n",
    "        cord.append(dist*cos(angle))\n",
    "        cord.append(dist*sin(angle))\n",
    "        coords.append(cord)\n",
    "        dist+=step\n",
    "        angle+=resolution\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate two sets of spiral data points with opposite angles\n",
    "data_1 = np.array(spiral(1000, 5, angle=0))\n",
    "data_2 = np.array(spiral(1000, 5, angle=180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD8CAYAAABkbJM/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA0IElEQVR4nO2de7RdVX3vP79zQiJ5QUgChiQHsBct0EdITjH4aodYRa2vXrWhvYLCNeIAq6UdQ1J6ex3tcPhoxQ60RUOlQKsgxVqpjyqgt1abgCcQlIdg0EAOicnJA8yDnuSc/bt/rLVy1tnZj7XWnnOvufb+fcY44+y99lp7zzXXWvM3f9/fb84pqophGIZhtGOg7AIYhmEY1cAMhmEYhpEJMxiGYRhGJsxgGIZhGJkwg2EYhmFkwgyGYRiGkQknBkNEbhSRXSLyUGrbSSJyl4j8JP6/IPXZOhHZIiKPichrUttXiciP4s+uExFxUT7DMAyjc1x5GDcBF9Ztuxq4R1XPBO6J3yMiZwNrgHPiY/5ORAbjY64H1gJnxn/132kYhmGUhBODoarfBfbWbX4TcHP8+mbgzantt6nquKr+DNgCnCciS4D5qrpBo9GEt6SOMQzDMEpmhsfvPkVVdwCo6g4ROTnevhTYmNpvNN52JH5dv70lixYt0tNPP91JgQ3DMPqFTZs27VbVxXmO8WkwmtEoLqEtth/7BSJriaQrhoaGGBkZcVc6wzCMPkBEnsx7jM8sqZ2xzET8f1e8fRRYntpvGbA93r6swfZjUNX1qjqsqsOLF+cykIZhGEZBfBqMO4FL4teXAF9JbV8jIrNE5Ayi4PZ9sXy1X0RWx9lRF6eOMQzDMErGiSQlIrcCvwUsEpFR4P8CHwVuF5HLgKeAtwGo6sMicjvwCDABXKGqk/FXvZco4+p44Bvxn2EYhhEAUvXpzYeHh9ViGIZhGPkQkU2qOpznGBvpbRiGYWTCDIZhGIaRCTMYhmE4p1ZTxvaPU3XJ25hOGeMwDMPoYWo15aIbNrLpyX2sOm0Bt757NQMDNi1cL2AehmEYTtlz8DCbntzHRE3Z9OQ+9hw8XHaRDEeYwTAMwymL5s5k1WkLmDEgrDptAYvmziy7SIYjTJIyDMMpIsKt717NnoOHWTR3JrZKQe9gHoZhGM4ZGBAWz5uV21hYsDxszMMwDCMILFgePuZhGIYRBBYsDx8zGIZhBIEFy8PHJCnDMILAguXhYx6G0Z/UanBgF+QNrhY9zshE0WC50R3MYBj9R60GN/8OXHsW3PT66L3v48zIeMWyq7qDGQyj+uRtkA/thm33Qm0i+n9ot7/jihqZ5FgzNG1JsqvO/8g9rFm/kVrN6ssXZjCMalOkQZ6zGJa/GAZmRP/nZFzmt8hxRY1TJ4amz7Dsqu5hQW8jHGq1qEGdsxiyatiNGuS5J7c+RgQu+Wr+3ypyXGJktt2bzzgVOa8i9dcDJNlVyfgNy67yh1eDISIvAr6Y2vQC4M+BE4F3A2Px9j9V1a/Hx6wDLgMmgT9U1W/6LKMRCEmPOmlYL/kqDGRwgIs2yAMD7RtgF8cVNU55z6to/fUAll3VPbwaDFV9DFgBICKDwNPAl4F3AZ9U1b9O7y8iZwNrgHOAU4G7ReSFqTW/jV6lSI8aijfI3aSIccp7XkXrr0dIsqsMv3SzC3IB8ISqPtlinzcBt6nquKr+DNgCnNeV0hluyRuwLRpXgKkGOURj0Ql5zqto/Vlg3chBN2MYa4BbU++vFJGLgRHgj1V1H7AU2JjaZzTeZlSJIvJIFTyFkClSf30sY9VqahJWAbpyd4jITOCNwD/Hm64HfolIrtoBfCLZtcHhx3R9RGStiIyIyMjY2FiDQ4xSKZoZ1KueQrfIW39Fr1PFsTTc4nSrO/Fa4H5V3QmgqjtVdVJVa8ANTMlOo8Dy1HHLgO31X6aq61V1WFWHFy/OIV0YxckjXXQiLxndo0+vk6XhFqdbktRFpOQoEVmiqjvit28BHopf3wl8QUSuJQp6nwnc16UyGs3IK12YvFQNispYFb+uloZbHO8GQ0RmA78NvCe1+eMisoJIbtqafKaqD4vI7cAjwARwhWVIBUCRDJyiaatdJK+O7Xv/UshznXok5mFpuMXxbjBU9RCwsG7bO1rs/2Hgw77LZeSg6FiHEsjaSOddrKcb+wffgPVQ6q6l4RbDRnob7amIxJSnkW6kY7dqQHzuX5mV5irUcTD8UD1/0nBD3vz7kjKY8sxCmieYmXexHp/7FwnCljI7a9JxuOpReOfX2t8LNsaj5zAPox+piBadt+edJ5iZV8f2uX/eIGypHknWmEdF7rEsVEIu7BJmMPqRkrXorA9gXhkob6OeV8f2tX/ecuetl1LokXhHZeTCLlFNk290Ron593kGTRVZ47mqK7blKXeeeiltYaEeGeNhYzamYx5GP1JiEDtP79jSHxuTtV5K7R1XJFGiHTZmYzpmMHqFvAOqShonkfcBtPTHxmSpl9KlqzzxjkANi3VapmMGoxcIIMCYNS5hD2D3KBJM7/p1CeDebYd1WqYwg9ELBBDEziN92APYHfIY59Lkqx4JjvcLYZlyoxglBxgtMBguWYPppV3DHgmO9wvmYfQCJQcYLTBYfUq7hj0SHIf+GK8hXU+3c8zw8LCOjIyUXYyeJM8D0A8PS6+T5RradW5MFcdriMgmVR3Oc4x5GKFTUgaJxSX6j3bXsNRGMeBMKgggI61LWAwjZJIMkmvPgpteH73vEhaXMOop7Z4o8TnISpFBplXEPIyQKTGDxOISRj2l3RMVyKTql3RxMxgh43E66XZadL88AEZ28owwd3rfVGRa9X6QZS3oHToetNsqBuiMauDt3go8hlFFigS9LYYROh7WobD4hOELb/dWSeuxGNPxbjBEZKuI/EhENovISLztJBG5S0R+Ev9fkNp/nYhsEZHHROQ1vsvXj/RLgM7oPqXeW7Zgk3e8S1IishUYVtXdqW0fB/aq6kdF5Gpggap+UETOBm4FzgNOBe4GXqiqk82+v7KSVMkutuXT0/4aZLlGJpUcg81J1ZjQnrkqSVJvAm6OX98MvDm1/TZVHVfVnwFbiIxHbxFAmmBV143ITLveZrtrkOUaZd2nz3q97e4tL2t0NMqkCog868CETDcMhgLfEpFNIrI23naKqu4AiP8nOXJLgW2pY0fjbdMQkbUiMiIiI2NjYx6L7gmPN3dpC+aERJaGvN01yHKN2u1jBuUYvDWcgc9J1Stxw24YjJeq6krgtcAVIvKKFvs26pIcc0ep6npVHVbV4cWLw7oxMuHp5u6VXkwmWjW0WRr7dtcgyzVqt48ZlGPw1nAmc1Jd9Si882vByYO9Ejf0Pg5DVbfH/3eJyJeJJKadIrJEVXeIyBJgV7z7KLA8dfgyYLvvMnYdTxOu9cv0BG316ix5++2uQZZr1G6fduVoNyCtArp8XrwO/itpUbAs9Mq4Jq8GQ0TmAAOquj9+/WrgL4A7gUuAj8b/vxIfcifwBRG5lijofSZwn88yloaHm7unRme3Cia3a2izGuR21yDLNWq1TzcMSsUC7r3ScBahFwb2+fYwTgG+HN8UM4AvqOq/i8gPgNtF5DLgKeBtAKr6sIjcDjwCTABXtMqQMqbTMw+jCw8ilN6mL4NSYe+jVcPpLZOogsY1RGyktxEeB3ZFun5tIooPXPXosY1uvzQAzc4zSx1VDK+jxCtqXH1SpbTa3sdTsLJnsqBa1U+WgHO/jPxtdp7t6qiCwXJvAfHAU26rhE0+6ANPPZqemQOqXf300Cps3mhVRxXtUXuLwVVg8sLQBvU1wwyGDzxNx9wzWVBZ6ieUGETINKujCkwH3ghvMbjAOyBV6giG3+2oIp7GWVQul7uZLBL4IKt6KicDVliu8jYDQcASZpUG9VnQ2xeegrJVcV3byiIlLj3bqP5abW/V+8v7fV2jWf1WVK6CAOrUE6rKmvVT99hta1d35fxsTe+Q8CSpVCaXu50sUoLk1Kzxb2UUWsmARb6va41ej8lVvbzORpXS4avRtegzKiWBBCg7Nau/Zq5/K0mglQyY9/taTd3StWve6roELFV5kW0CmAQ0oSqTgZqH0Qn9vhpeK3mjC4HGRr31VvXXLAunVXZOq95f3u9r5q109Zo3uy6BS1VeMqgq6m2ViRmMonh6wCqVCVWi7NSskW1Vf80a/3aSQDMZMO/35TUkyXk6lyoaXZfAG08vsk0F0m1DwwxGUTw9YJWaD6oLD1yzBrNZI9uu/po1/kVjQ3m+L68h6arnUYHG03n8LvB02xAxg1EUTw9YlQJgvh+4IvJS6PWXx5C0krC6NlYhgKBwKzqui8DH+4SWGWYGoygeG8sgM6GaNRweH7gi8lJUpADrrw2NytzIKHr1OuqvZeBxjUrF+woQ4vmZweiEwHsnzuhCw9GoJ1VUXuoVGhnF3QfGu+d1BB7X8BbvC8SrCjGeaQajREJzN5viueFo1pMKXV7qBvVGsateR+BxDS/xvoC8qhDjmWYwSiJEd7MpnhuOVj2pXvci8pLH63DwY0HHNbx0KALyqkLsMIUjSPYZwc4f02jwluP1kusHqVVujqySqR/k1az+nAwGrJ+DKaDBblHxHA94C2yes9AG9JmHkQUPPaoQ3c2W7rijeE0zzyq0nlSVaNQT9ebBBtQDb0THMq+l2rbEq4chIstF5Dsi8qiIPCwi74+3f0hEnhaRzfHf61LHrBORLSLymIi8xmf5MuGpR5U85BvWXdC1ycba0oWFZpp5VqH1pKpGff1582AD64GnaTX1Si4Cntm2bHxLUhPAH6vqWcBq4AoROTv+7JOquiL++zpA/Nka4BzgQuDvRGTQcxlb47ERDa6R9NAYmPxUDo3q2YlE1UieDGQOqmBl3h7CqySlqjuAHfHr/SLyKLC0xSFvAm5T1XHgZyKyBTgP2OCznC0JPFPEKY7dcZOfyqNeplLFnUSVlictq6iv6FoMQ0ROB84F7gVeClwpIhcDI0ReyD4iY7IxddgorQ2Mfxw0osGmzzaKzTgcW9Is+8kyn7pDup69ZVIFFNPwllUUSFZYVJRy25KudAVEZC7wJeADqvoL4Hrgl4AVRB7IJ5JdGxx+jJ8rImtFZERERsbGxvwUOk0HmqYzXdU1HmIzJj+FS/21OGn2cW6mUw8spuFc5g0oKyyEtsS7hyEixxEZi8+r6r8AqOrO1Oc3AF+N344Cy1OHLwO213+nqq4H1kO04p6fkrshxNGagPOeoclPYZPufZ80+zh+/+/vdSNP1XvgqnBwLIjeuBMC8qBCaEt8Z0kJ8DngUVW9NrV9SWq3twAPxa/vBNaIyCwROQM4E7jPZxl9E2wv23HP0LKfwie5FnsPHXEbHE48cNVgeuPgaBxKQB5UCG2Jbw/jpcA7gB+JyOZ4258CF4nICiK5aSvwHgBVfVhEbgceIcqwukJVJz2X0SshjtYEnAe4ezbgWK9fB6RnF6X+WiXyVMf3Z0C9cWfjUAIalxFCWyKVWAa0BcPDwzoyMuLuC3ugQWiIp9UB6weLBWcYs9DMKBy/EG55w1QG0MV3wi1vnP7+ub1TUkyF7pvkWjmVp1QjzyKpHwezAhRlbP8453/kHiZqyowBYcO6C8KQggNCRDap6nCeY2ykd5qAUgSd4uG8mvXgKvNQZjEKp54LT98POhm93/349B70P1wI2x+AZedF3zl6X2UMSXKtxvY7zJ5K98aPX1hqLKNnPd6SMYORJiCX2ikeziuEAFwu0l5EorW3MwrbH4ClK6P/y18Mi395akxO+rjReyNxNfmOLIYkEOORblhXDi1AVVHV4h7iwADMXlR6xysE+aYX6YHus0McBbicBNtc4iFwF0IAri3JCOTJyenB2IO7jjUKSd0kRiF5/65vTo1qHhiYGuV86bdgaHW83+qpYxJDUpuIDEm9R3LtWfAPr4P9Py99ZDRMNazf/+ArAeUlH/125ymbXZhiJgteEi4CGdVeFhbDqKdDrT/Yacu7EMMIirQMl/YGBmbAHz0Cd7wrJUP9Gzy3J39gu95rObT72N61auRhpMuAgAxEBicQ2dOp5h9QLCPByb3aY5K1xTBc0OFI52ClGgcjuOsfuiBjFkkjrtpcWpp78rGZL+m6yVpX6f3S31E/LmGaIdkItckp+Wrsx3DyWaU3qE41/4Ayi8BhJy4gybqszpoZDMcEFWxz6FUE6zmlqe8BLjsvFT+o8yLqjYRLWhmSg2Pwz++MynXcbPjMy6Lyve0fYO4ppTWu9QP7dh/osDFK6qBWK30gn7NOXCDzypX5LJrBcEwwwTbH7nOwnhM09iq23QsfeDg650ZeRBkMDMC8UyKJZuzHkbHQSXhqA1x7dumGY2BAWDhnprvGKBAJx1knLhDPqcxn0QyGB4KQahy7z0F5TmlaeRXzyuuxt2RgIJKhhlZPl6gSw1FibMNpYxSIhOO0E+dwcs6ilPksmsGA3hys58h9TmulQXhOUwXL5lWEStJbPSpR3ZuKbWyMts87pevFShqjkSf38avLTmDhnOOKf1kgEg4E0olzRJkqhmVJBeI2e6GXM74aZSJ5zMhJj4zee+jI0f9OHthE57/9kshYoLB0GC77Fgx0f/2wiYkab1+/gQe3PcPw6Sd1Lkv1WmesR87JsqSK4MhtDjLFtBczvmq1SP9/auNUppFDr6KRYdh94DDvu/V+Nj31DLNnDnJwfII5s2ZwcHyCX19+Ire/ezV7Dx1BhGJ5/0ls4+03RZKUTsLTI3Dja6LxHl3uwOx77gg/HH2WSaXz654M5AtgBltLre0cMxgO3OageuIOez/BxS3SD+vMOXD4oLNYRTLYsplhSMax7f/viWn/H3jqGVb85V0cPBzNkbli+Ql86fKXMDhYoBGZe0qU/jv6g+j905tKkaacXvdAGtheTK0tAzMYDjIfgumJO344g8n4gmM9iyOH4PLvdTyGod5QTMaWod4wAAwIRw3I8TMHOTgeGYnEWABs3vYsb/3Mf/Hht/wqv/z8eQzkqX8RuPSb8LlXRx6G1qL4RjLKvEsk131s/3jnDkEgDWyvpdaWhRkM6Fi6CaYn7vDhTLvvQchQjTyLDoxFM0MB0w3DnFkzODQ+warTTuLTv38uC+fMZO+hIyw4fgZvX7+RzdueYc6sGdMMywPbnuV1132PObMG2fxnv81xx+WIQwwMwtv/ET55VvT+qQ3RVBTzn1/oPDvhD297oPMeeSANbK+l1paFGQwHBNMTd5gZFYzEBtMNoQPPIgnqbt72DCk7waBwjGFoFNxODOgdl78kNdBtnMv/aRMPbnuWZNmgg+OTvPa67/Lv738FM2bkNBpHKScpxVmPXCSadHH349E8XQEMTOyF1FooJ27aP9EazwSxslzS+0kmyytYlmar55VCrRZlQS07b2pCwILGolZTdj7737z1s//F/U9NGYtBgfNOP4kN6y7gi+9Zzcnzn8fg4ACL5806+r/RdU2u+eDgAKeccDxfeu9L2bDulcyeOfVYbRk7xK//5V1MTORYfW7uybD8/Kn3d7yr66vXLZo7k5VDCxgcEFZ20iOv1aLp4j/78shLLHEVviCeUUeUtb63eRi9hoPeTzASW1qKWnYe/NHDhUdBJw/YyJP7pslP5y4/kc++Y5WThmRgQDjlhON58P+8mtde9122jB0CIk/j8V37OfvUE7J9kSpMpoz06H1d1/6jbHuNXqiiWrD/EUgMo9coK24anIchIheKyGMiskVErvb6Y702VbGj80nc9w3rLuC2tavL65Ed3BUFuWsTUaMpA4W9prED44xs3XvUWAwInDt0Il967/mcPP95Ts/xuOMGuemdvzFt24nPy9E3O7ALtm+aer/k3K5r/3sOHub+p55hUuH+p54p7mUGtCa2s2UHAmg3ylpeICgPQ0QGgb8FfhsYBX4gIneq6iPOf8xhRlEQYzB68XzuuDTKFILIwyjY2ExM1Lj8nzYxGT/fv3HaAv72D1Z6kydqNeWJPQenbdv33BFOzfoF9WX6vX/quvafSFKbntrXmSQVSJDYWVwukDThsuKmQRkM4Dxgi6r+FEBEbgPeBLg3GA4H7AURIO7V80GjIPDbbiosRb1t/QYeeOoZIPIs/vYPVnLy/Oc5LS61GhPP/pyfjB3g6n//OQ9u3z/t40Vzc8gFx58Ex82BIwdh5rxSeuXOJKlAcCbhBCSxlTHdSWiS1FJgW+r9aLzNPY5c5WACxL12PrMXRosOyWC0ol3Bh3LswDgPbnvm6PsVy090/5DVatRufC2Df3MWL/r8b7Bu7E8QpoK75yyZm91ATU7A514VGQuIssKe2+O2vBlwJkklPfJktcOSgt7OJJyAJLYyCM3DaNSHOUYoFJG1wFqAoaGhgr/kxlUOJkDcS+dTq8HNb5ha+OiSfyvsXbzv1geOZkOtWH4Cd1x+vnv3/cDPkdGN0TIbwKqBx1jIfnZzAnNmDXLnlS/L9puTE/D3F8COzVPblq4spVFydh8E0iN3JuEEIrGVRWgGYxRYnnq/DNhev5OqrgfWQzT5YOFfc5BRFMwYDOid80k3MtsfgEN7Cp3XnoOH2bR1LxBJUevfMZxv5HVWDowdfakKj9SWsfTUpdzy1hXZR3s3MhZLVkRzSZVwDVThuovORSg4P1ZCIAP3wKGEE8g4jDIIzWD8ADhTRM4AngbWAL9fbpHaE8TUyY7mkAoi4D1ncRTkTtJpCzYyJz5vBs+Lp/CYM2sGC+f48pZkyjUWOGvxHP71kjOR+fPbrwl+MM62uf0dxxqLd38nmHmXCt8KqvDWG4F4AasSg96l39c9QFAGQ1UnRORK4JvAIHCjqj5ccrHCx1HmRjAB7yRdUYgamAIR11pNefsNG6fmexqfYO+hI34Me6q3KcDMvY9FU3ucuiqa5mNgIEoJnhPP2pqc3x2XwlP/dez3lWgswGGAuNF9WUJjHcx97RBb0ztGVb8OfL3sclQKRzpxMJMoHtodjbuoTRY+nz0HD/PD0WePvv/1ZSf4i8fMOyUamb1tw/Tt2zfB35w99X7mPDg8PXtqGjIAS1eVMqV5Qq2mqCorT1vA/T0Sv3B6XwewFkaZBjC0LKnu4XDwjbMBQUVxlLlR1mCgY0gkKRksLEktmjuTVUMnHn1/3OCAv3FWIvCur8NVP44WPmpGU2MhMPSS6PjL7irVWFx0w0Ze8tFvgyrf/+ArOxu4GUhGkbP7OpCMrzIzGYPzMLqC40Fupbu7jjI3ggh4gxNJSkT41EUrOf+j91BzsRBQOwYGYP6SqME/sBO++L+iKcrTTPMwBIbOj/R9GShV309IN0T3P/UMAwPS2UJDh3ZHGW6H9pTaI3d2XwfiMdma3t3G4YUPRsbppcwNB5IURA9WMvX47FkzOGl2B+tTZyVtOA6mPNj6GEYgRiLBqRQVSOwijZPElEAyvsrs2PWnwXB44YMYtwBOtNUgvCVwliW199ARDh2eCnrvOXjY/QjvZgwMwLwGa1g02lYy6eu+cuhEvv/BV3Ly/A5SaQPpiTsnoDEYZWVm9qfBcHjhg5BxHElswXhLDiQpmIpj3Ld1HzWFK299gNt6IEPGJbWa8vjO/Udn8e1YioJgeuLgIZuolzz5AvRv0HvAnSRQ+jz7jXp0BQgm6N1IkipAEscYjA3Epq172X1g3GVJK03iWbz+uv9k9sxBBl0EhQ/sil47WJelU8paM6KX6V+D0Us4ykYJZlrz5HxkMJpPavaiwl918vxZR7OlJmMvwxqOiMSjnFQ4ND7B1973suLXvT6DCEqP0TjLJgpgOvNQMIPRCzhaaQ8ib2nhnJnsPnC4vDThZFnPpSujqUE6WKnNvIxjSdLAF8457qhHOXz6Sbzo+fPcxi1KxonHHEgqbVSUktP36dcYRi/iSFsNJvD93N7IWDgInCZexn1b9x31Mvo1llF/fT9/2YvZ99yRzjX+gOIWCU7ii4EE8EN5Ls3DcEQI1j8uSEfuczDTm6dltmXnHV2XoQiNvIzHd+4v/1p1keT+3H1gfNr13ffckc7ib4HFLerpOL4YyODDUJ7L/jYYjrTJYIJrDtznYALficz2Rw9Hrz95dkeSwMnzZzF82gIGBWbPmsHrP/U9fu+zG9j57H/3vOFI359XfuF+Vg45ur4Bxi2iYjnsvDmUezshlOeyfyUph6O9g0lHdeA+B5EmnJBM2udAEkjO6/Gd+3n9p77HZE25b+s+XvKxbzPcIxPS1ZOklKrqtBHc37/6lQyIdH59A5Fr0niRbgJIpQ3luexfD8NhkC4U6+/KfU7ceFXKl9kcSlMDA8KLnj/vqKcBMBkb+bED4+Wfq0NaeRUnz5vlJg08ELkmTSjSjQ9KT98HpOoPyPDwsI6MjLTfsR7VyI1OPIwO3c1g5tt3uC5GCEG2uDDRNBt3XOps/q/dB8a58tYHuD8e3YzI0defumhlZyOdSyJ9D+4+cJjzP3IPEzVlxoC48yqiH5q6x1SDGPmcoKqsWT9135aaHh44IrJJVVvMlnks/StJOR7mH8QiSlFBnLjPwchs4FSair5OOHn+87gtdvFVlZd89NtMVFimqjfwX/jfL542Zc3JrnqmjaTcgEY+O5NuApjGPET612BAENqkNzq84YOZIyuhPm1z9sIoYaGDB3pKelNWnbaAka17mdTpMpWzXrkH0h5FvYHfe+iIH807wLhFPR133hzGN3uN/jYYvYqDGz6UIFuqQFMe4eyFcPMbnD3QybnWy1Tvi18nkhxQan2kDYQqLT2KpIxOvMJ05yPA8RbO5eAKGMWy8GYwROSvgDcAh4EngHep6jMicjrwKPBYvOtGVb08PmYVcBNwPNGqe+/XigVZgohlOLrh0z21IM4r8QgP7Jp+fgd3xdOHd+ZtNJOpEm/jD299oOmANx/108pAXLfm3O54FI06H4HM2BoVz0OsLSCjGMRzl8Knn3UX8Cuq+mvA48C61GdPqOqK+O/y1PbrgbXAmfHfhR7L55xgxmM4zl4J5rwS6jOn7rjU2dQNiZFcPG/WtMw3gaMN9MjWvbxt/Yaj9TExUTumfurHArR7X7+tvs7H9k8fcCfCMZl5XrJoGnU+HE7c2SlesqICGXsR3HOHRw9DVb+VersReGur/UVkCTBfVTfE728B3gx8w1cZp+EgyBVMoNhxQD+Y80pIn59qNKjPsXxQL8kBRyWfX1t2Ag+OPns01rFl7MC0+mnkjfzB5+5t+j6Ru1p5EImBSD5fPG+WP48ifd8E1NtuhLdYWwDxzeCeO7oXw7gU+GLq/Rki8gDwC+DPVPU/gaXAaGqf0XibfxwFuYIKFDu84YM6r4Tk/FSdB8OnfmJ6DCBpoBfOOY6Lbphq8F94ytxp9ZP2RhoZlPr3Sa84r4EQwW0D0uw5CEiCqie4WJtDQnzuOjIYInI30GgJsWtU9SvxPtcAE8Dn4892AEOquieOWfyriJxDtFxOPQ19MBFZSyRdMTQ01MkpRDjS/IO9eTv0nurPSxV2HxgP4xw9BsPrSRuQ+uvczBtpZFDq3zc6pisGop5mz0EAve2ERpq+k6yoAA1iiO2J14F7InIJcDlwgaoearLP/wP+BHga+I6q/nK8/SLgt1T1Pa1+o/DAvTSOB/EFheMUwaAG9NVzYFcUy6hNRPGNqx6N1tIooTGob9javW90TBcKOb1uAn8OvNx7fZxCG9TAPRG5EPgg8JtpYyEii4G9qjopIi8gCm7/VFX3ish+EVkN3AtcDHzKV/nqChu0290RjlMEQ9RVj9JorEZJjUF9r7fd+2bbvFFB+cnLvWcptLnw+fR8GpgH3CUim0XkM/H2VwA/FJEHgTuAy1V1b/zZe4G/B7YQpeJ2J+ANQWV+OMVxxlQw82Y1oj675dCeYxuDfl09rf68m82lFvBz4OXeC3A+rJDp37mkukQQedSONdogzikL9RLLJf/mNcYRLI28CZGg5admeLn3Ao1h+CYoScoISO93HLSsl06CNSD1UuPBscbyQy81GI3OpZnsErD81Awvsl0AQf1gn6E6+qB7VR7BTrXsUJYJcXDRNNISSyP5odmiU1WQrurL2OxcmskuActP3lawDPC6Bv8MpTAPoxkOep0h5lG7zgoJOgheT6PkhkZex+xFzeuoDG+k0W82uo7NPImKJXV488wDzYiq0jNUfm2FiIOlTmEqj3rDugvCmZff4cJREHgQvBH1vepGve9mdZTXG3GxvdlvNipjqwBuwN5EPd48c8f3viuq9AyZh9EIh6l2wayTkeB4qodmg4uqosk27H03q6NG90Uzb6RZbzbv9mb3YqMyVsyTaIY3zzzQaU5CHKDXDDMYjQj0xnKCh0alURA8iGB/VuqDns3qqNF90SyQ3qyhz7u92b3YrIwBBHDz0Khj4a0BDdigBtexbIIZjEYEfGM5oVGj4lCbr5Im25RGdZTHG3G1vdW9WDHjUE+rjoW3BrTidVY2ZjCa4fHGCk6ucRwMDDLY74qs3oir7Y1+s0fw1rHopTTpwDCD0WWClGscT4/QSlIIzli6oFmD7mp7j+KlYxFoJlSvYAajywQp13iI2TSSFII0lkZpeIlVBD43VNU7TGYwukyQck2XYjZBGkvDO60aSeexioATVnqhw2QGIy+O15YIppfRBTkkSGNpeKXrjWTACSu90GEyg5EHR/poVVLojuIoiNh3sQ2jnEYy0FhQL3SYzGDkIXB91AuOg4gW2+gvvAW2A/Qg2hGsupADMxh58KyPBtnL7oKR7AVXvZ9pdd86byQrngVVOXWhDjMYefCojwbby+5CELFdLzRIQ2oA2e5bp41kP3r5AWEGIy+e9NFge9ldCCK2i20EaUgNoIT7NuAsqH7Amy8nIh8Skafj5Vk3i8jrUp+tE5EtIvKYiLwmtX2ViPwo/uw66aPuZNAzVjab6dTh2gJJL7T+kge7pkgf0Wptiq7ft/XL8AbWRHhbxyMQfHsYn1TVv05vEJGzgTXAOcCpwN0i8kJVnQSuB9YCG4GvAxfSzXW9S6RyAbEuaclZgqYmWfmjnYfn5b5tF9QONAuqH7zhMiSpNwG3qeo48DMR2QKcJyJbgfmqugFARG4B3kyfGAyoWECsS1pyuwapHx7SMskiOTm9bysc1A5WVnaI7ytxpYj8UERuFJEF8balwLbUPqPxtqXx6/rt1SHA5R+90WqxHsc0k6sgm2TV6zJBpwQlOQW6yFEWgpaVHdGRhyEidwPPb/DRNUTy0l8CGv//BHAp0Kj7py22N/rdtUTSFUNDQ7nL7YUK94wKkSUY3oV8+SwZVuaBNKcUyakVFQ5qV05WLkBHBkNVX5VlPxG5Afhq/HYUWJ76eBmwPd6+rMH2Rr+7HlgPMDw8HEa30bNEE6RO30pL7pIBbfeQZpEJgqxbR7Q7t65LTu0IeGqPLFRKVi6AzyypJam3bwEeil/fCawRkVkicgZwJnCfqu4A9ovI6jg76mLgK77K5xyPEk3SCzz/I/ewZv1GarUwbGRLuigttJKs2skElazbmHZSW5Zz67qMkkW2rdD64/2Gz6D3x0VkBZGstBV4D4CqPiwitwOPABPAFXGGFMB7gZuA44mC3dUJeHvsGVUymBaItODCA4FsXogrTyXrb7WT2rKcW1dllArLtr3shebBm8FQ1Xe0+OzDwIcbbB8BfsVXmbzjKd2vkpOWZTWgXYhztJIJsqbttmucs8ZK2jU8Wb8nizHIet90TUap6Chti4NNYSO9K0Blg2ntDGgAPc4sdZulcc4aK3HhFUA2YxDcfROI15mXSnr4njCDURF6MpgWSI+zXd1maZyz7OPSK8hqDLp232TxFCsa0K6kh+8JqXpu+vDwsI6MjJRdjGx4ll8qp7Oqwk2vn+pxNpvqIYDprF3EMFSVNeunPIzb1q5uKktV6joG4Cn6pnLXJAMisklVh3MdYwajS3h+qCqrs7YzBj3WGPViw8OBXXDtWZGnODAjmuepArGJfqeIwajuk1c1PKeZVnaSvnYplBUe+duIVinAQZIlDbaLo/6NcjGD0S08P1Q9Oy1B1nrrp2lZukXi3V17ViQd1mqN9wt8BtlW2LQx+TBJqptYDKMYfSZbBUOPS02VlXEdYZJU6HgewVo5uSMrLmUr80QiTGqqroxbIpZW22f0pBeSNb/fPJGIrPVQ0TTYrFi6bH7MYPQRPeuCZ23Y8o77CCCdNxdZy5unHgJdrMgFwQ1srAB92L2qAJ5kk552wbPIfXkklqwB3/T+Wa+Zj33zlLfHpaY89KyM6wnzMELDo2zS9y54HoklTy88zzXztW+e8va41GT4wwxGaHicLsNccLJLLHnmPcpzzXztm3eeph6WmnoyThcIZjBCw/MEbT05J5UP8vTC81wzX/ua1wD0cJwuEGwcRogEEmy1nloO8lwzX/sajO0f5/yP3MNETZkxIGxYd4F1kJpg4zB6hQBWHKvySnSlkOea+drX6N0ZDwLBJCmjIbYGgFFFLE7nF59ren9RRDbHf1tFZHO8/XQReS712WdSx6wSkR+JyBYRuU7sarfHUwqu9dSMUMg735OlyvrD5xKtv5e8FpFPAM+mPn5CVVc0OOx6YC2wEfg6cCFVWte723hMwbWemhECFsQOC+8xjNhLeDtwa5v9lgDzVXWDRl2JW4A3+y5fpfE89XfenprN/Gm4pqcHm1aQbgS9Xw7sVNWfpLadISIPiMh/iMjL421LgdHUPqPxNqMZAY3YtSC54QOTRsOiI0lKRO4Gnt/go2tU9Svx64uY7l3sAIZUdY+IrAL+VUTOARp1Yxu2OiKylki6YmhoqGjxq09AufcWJDd8YNJoWHRkMFT1Va0+F5EZwO8Cq1LHjAPj8etNIvIE8EIij2JZ6vBlwPYmv7seWA/ROIwOTqH6BDJit++nHTEyUWRsjw02DQffabWvAn6sqkelJhFZDOxV1UkReQFwJvBTVd0rIvtFZDVwL3Ax8CnP5es/PA0EK9ITtIGB/YUFsKuPb4OxhmOD3a8A/kJEJoBJ4HJV3Rt/9l7gJuB4ouwoy5Byief1IPL0BK3x6D9Mtqw+Xg2Gqr6zwbYvAV9qsv8I8Cs+y9TXeJzYMC/WeFSbIt6hyZbVx0Z69xOeJzbMQ9HGw2Ss8inqHVoAu/qYwegnAsqqKhrzMBmrfDrxDi2AXW1s8sF+I6DJ7PIODLRBXH7IO+DSxkb0L+ZhGO0JZIptk7HcU8RrM2mpfzGDYbTGc2ZVHkzGak5Ro1hUXjJpqT8xScpojef5qvLSTRmrk7mxih5b5LhOpmUxecnIg3kYRmsCyqwqQicyVlHPpOixRY/rJAgdlLwUiPRpNMcMhtGaoplVgTz8RRvEThrhoscWPa7T8Q1ByEsBSZ9Gc8xgGO3JO19VYA9/kQaxk0a46LFFjwvKSyhKQINKjeZI1dcuGB4e1pGRkbKLYaQ5sAuuPSt6+AdmwFWPVvLh7yS7quixfZvRpQo3vX6qk/HOr5ks5RkR2aSqw3mOMQ/DcE/F4x4JnUg1RY8NQh7qhKJSZECDSo3mmMEw3NPpwx9I/MPISadSZCBT9RvNsaiS4YeiI8qTRufasyKJolbzUz7DPYGlYBvuMYNhhIU1OtUloCWDDT+YJGWERafxD5OzOqOT+rM4RM9jBsMIi04ancDSeSuHi/qzOERPY0+TER5F4x8u5KxaLUoLrmq6eSflNznQaIMZDKN36FRDdxFw79TgdHJ8p+W3GITRho4Mhoi8TUQeFpGaiAzXfbZORLaIyGMi8prU9lUi8qP4s+skHp0kIrNE5Ivx9ntF5PROymb0IYmcddWjxQZ+ddrD7rTB7vT4Tsvfaf0ZPU+nHsZDwO8C301vFJGzgTXAOcCFwN+JyGD88fXAWuDM+O/CePtlwD5V/R/AJ4GPdVg2ox/pZIGoTnvYnTbYnR7vwkMIaIEtIzw6Cnqr6qNAoykM3gTcpqrjwM9EZAtwnohsBear6ob4uFuANwPfiI/5UHz8HcCnRUS06nOXGNWh0yyfTjO8Oj3espQMz/jKkloKbEy9H423HYlf129PjtkGoKoTIvIssBCwyJvRPTrJ8um0wXbR4FuWkuGRtgZDRO4Gnt/go2tU9SvNDmuwTVtsb3VMozKtJZK1GBoaalIEwyiBThtsa/CNgGlrMFT1VQW+dxRYnnq/DNgeb1/WYHv6mFERmQGcAOxtUqb1wHqIZqstUD7DMAwjJ77Sau8E1sSZT2cQBbfvU9UdwH4RWR1nR10MfCV1zCXx67cC37b4hWEYRjh0FMMQkbcAnwIWA18Tkc2q+hpVfVhEbgceASaAK1R1Mj7svcBNwPFEwe5vxNs/B/xjHCDfS5RlZRiGYQSCLaBkGIbRhxRZQMlGehuGYRiZMINhGIZhZKLykpSIjAFPll2OFiwi/LEkVkZ3VKGcVkZ3VKGczcp4mqrmGh1aeYMROiIyklcn7DZWRndUoZxWRndUoZwuy2iSlGEYhpEJMxiGYRhGJsxg+Gd92QXIgJXRHVUop5XRHVUop7MyWgzDMAzDyIR5GIZhGEYmzGA4Il4tcHP8t1VENsfbTxeR51KffSZ1TMPVBz2W8UMi8nSqLK9LfZZrhUTP5fwrEfmxiPxQRL4sIifG24OpywZlvjCuuy0icnU3f7uuHMtF5Dsi8mi8Gub74+25r30Xyro1vmabRWQk3naSiNwlIj+J/y8oq5wi8qJUfW0WkV+IyAfKrksRuVFEdonIQ6ltueut0DOjqvbn+A/4BPDn8evTgYea7HcfcD7R1O7fAF7ruVwfAv6kwfazgQeBWcAZwBPAYBlljH/z1cCM+PXHgI+FVpd1vz0Y19kLgJlxXZ5d0r23BFgZv54HPB5f39zXvgtl3Qosqtv2ceDq+PXVqWtfWjlT1/jnwGll1yXwCmBl+lkoUm9FnhnzMBwTW+m3A7e22W8J8eqDGl29ZPXBMji6QqKq/gxIVkgspYyq+i1VnYjfbmT6lPjHEEBdngdsUdWfquph4DaiOu06qrpDVe+PX+8HHmVqkbJGNLz2/kvasjw3x69vZuo6ll3OC4AnVLXVIOGulFFVv8uxSz/kqreiz4wZDPe8HNipqj9JbTtDRB4Qkf8QkZfH25bSfPVBn1wZSz03ptzWo6sd1pWlrDKmuZSpGY0hrLpMaFZ/pSIipwPnAvfGm/Jc+26gwLdEZJNEi6IBnKLRMgjE/5PVpMqu4zVM7wSGVpd5663QM2MGIwcicreIPNTgL92bvIjpN9YOYEhVzwWuAr4gIvPJscKgwzJeD/wSsCIu1yeSw5qUxUsZM5Qz2ecaounxPx9v6mpd5qDs3z8GEZkLfAn4gKr+gvzXvhu8VFVXAq8FrhCRV7TYt7RyishM4I3AP8ebQqzLZjh9tn2t6d2TaJvVByVaKfB3gVWpY8aB8fj1JhF5AnghrVcf9FbGVFlvAL4avy2yQmJHZKjLS4DfAS6IXeau12UOmtVfKYjIcUTG4vOq+i8Aqroz9XmWa+8dVd0e/98lIl8mkm92isgSVd0Ryya7yi4nkUG7P6nDEOuS/PVW6JkxD8MtrwJ+rKpHXT0RWSwig/HrFxCtPvhTbb36oBfiGynhLUCSZVFkhUSf5bwQ+CDwRlU9lNoeTF3W8QPgTBE5I+6NriGq064Tn//ngEdV9drU9lzXvgvlnCMi85LXRIkODzF95c1LmL4iZ9fLGTNNNQitLlO/nbneCj8z3coy6Ic/opUEL6/b9j+Bh4kyFe4H3pD6bJjoZnsC+DTxQEqP5ftH4EfAD+MbaUnqs2vicjxGKlui22WMf3MLke66Of77TGh12aDMryPKSHoCuKbEe/BlRNLCD1P197oi195zOV8QX8cH42t6Tbx9IXAP8JP4/0kll3M2sAc4IbWt1LokMl47gCNEnsJlReqtyDNjI70NwzCMTJgkZRiGYWTCDIZhGIaRCTMYhmEYRibMYBiGYRiZMINhGIZhZMIMhmEYhpEJMxiGYRhGJsxgGIZhGJn4/1R/mRnZOc4WAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the two datasets to visualize the spirals\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a, b = data_1.T\n",
    "plt.scatter(a, b, s=5)\n",
    "\n",
    "aa, bb = data_2.T\n",
    "plt.scatter(aa, bb, s=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_76609/2939864048.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df1.append(df2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    201\n",
       "1    201\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two spiral datasets into one\n",
    "\n",
    "df1 = pd.DataFrame(data=data_1, columns=[\"X\", \"Y\"])\n",
    "df1[\"CLASS\"] = 0\n",
    "\n",
    "df2 = pd.DataFrame(data=data_2, columns=[\"X\", \"Y\"])\n",
    "df2[\"CLASS\"] = 1\n",
    "\n",
    "df = df1.append(df2)\n",
    "df['CLASS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, build a neural network with Tensorflow to classify `df`. See how low data loss and how high accuracy can you achieve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-05 18:43:35.033430: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-05 18:43:35.033456: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-05 18:43:35.793471: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-05 18:43:35.793608: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-05 18:43:35.793619: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#Your code here\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the features needed\n",
    "\n",
    "def create_features(x,y):\n",
    "    return pd.Series([np.square(x),np.square(y),np.sin(x),np.sin(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X1²</th>\n",
       "      <th>X2²</th>\n",
       "      <th>sin(X1)</th>\n",
       "      <th>sin(X2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.975021</td>\n",
       "      <td>0.499167</td>\n",
       "      <td>24.750832</td>\n",
       "      <td>0.249168</td>\n",
       "      <td>-0.965710</td>\n",
       "      <td>0.478694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.800666</td>\n",
       "      <td>1.986693</td>\n",
       "      <td>96.053050</td>\n",
       "      <td>3.946950</td>\n",
       "      <td>-0.367099</td>\n",
       "      <td>0.914754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.330047</td>\n",
       "      <td>4.432803</td>\n",
       "      <td>205.350257</td>\n",
       "      <td>19.649743</td>\n",
       "      <td>0.981456</td>\n",
       "      <td>-0.961170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.421220</td>\n",
       "      <td>7.788367</td>\n",
       "      <td>339.341342</td>\n",
       "      <td>60.658658</td>\n",
       "      <td>-0.415358</td>\n",
       "      <td>0.997848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1        X2         X1²        X2²   sin(X1)   sin(X2)\n",
       "0   0.000000  0.000000    0.000000   0.000000  0.000000  0.000000\n",
       "1   4.975021  0.499167   24.750832   0.249168 -0.965710  0.478694\n",
       "2   9.800666  1.986693   96.053050   3.946950 -0.367099  0.914754\n",
       "3  14.330047  4.432803  205.350257  19.649743  0.981456 -0.961170\n",
       "4  18.421220  7.788367  339.341342  60.658658 -0.415358  0.997848"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#First I will separate the features from the target\n",
    "\n",
    "X = df[['X','Y']]\n",
    "y = df['CLASS']\n",
    "\n",
    "#Now, I will prepare the the features as in my model, changing names and adding new columns\n",
    "\n",
    "X = X.rename(columns={\"X\":\"X1\",\"Y\":\"X2\"})\n",
    "\n",
    "X[['X1²','X2²','sin(X1)','sin(X2)']] = X.apply(lambda x: create_features(x.X1, x.X2), axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.87329272e-01, 5.16424651e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.99987993e-01, 5.00006680e-01],\n",
       "       [4.90031702e-01, 5.16689053e-01, 2.77863669e-05, 2.62130037e-07,\n",
       "        1.71084705e-02, 7.39358776e-01],\n",
       "       [4.92652990e-01, 5.17476977e-01, 1.07833355e-04, 4.15227940e-06,\n",
       "        3.16429425e-01, 9.57393167e-01],\n",
       "       ...,\n",
       "       [6.50799336e-01, 1.68491993e-02, 1.01671544e-01, 9.35811225e-01,\n",
       "        1.95902075e-01, 1.87879900e-01],\n",
       "       [7.02209104e-01, 3.28286721e-02, 1.75676742e-01, 8.76902751e-01,\n",
       "        3.71920155e-01, 3.05739926e-02],\n",
       "       [7.51969458e-01, 5.38503127e-02, 2.66461547e-01, 8.02322817e-01,\n",
       "        3.80735479e-01, 5.32714220e-01]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = MinMaxScaler() \n",
    "X_scaled = scaler.fit_transform(X)\n",
    "display(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(201, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(201,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(201,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the training data and the test data\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.50, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=1)\n",
    "\n",
    "display(X_train.shape)\n",
    "display(X_test.shape)\n",
    "display(y_train.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "model = Sequential([ \n",
    "  Dense(7, activation='sigmoid', input_shape=(6,)),  \n",
    "  #Dense(7, activation='sigmoid'),      \n",
    "  Dense(2, activation='sigmoid'),   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),#tf.keras.optimizers.SGD(learning_rate=0.1),\n",
    "  loss='categorical_crossentropy', \n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7505 - accuracy: 0.5124\n",
      "Epoch 2/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7753 - accuracy: 0.5473\n",
      "Epoch 3/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.4776\n",
      "Epoch 4/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7291 - accuracy: 0.5174\n",
      "Epoch 5/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7112 - accuracy: 0.5423\n",
      "Epoch 6/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7213 - accuracy: 0.5274\n",
      "Epoch 7/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7068 - accuracy: 0.5622\n",
      "Epoch 8/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.5224\n",
      "Epoch 9/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7664 - accuracy: 0.4975\n",
      "Epoch 10/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7445 - accuracy: 0.5075\n",
      "Epoch 11/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7637 - accuracy: 0.5124\n",
      "Epoch 12/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7161 - accuracy: 0.5124\n",
      "Epoch 13/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7044 - accuracy: 0.5224\n",
      "Epoch 14/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7193 - accuracy: 0.5224\n",
      "Epoch 15/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7151 - accuracy: 0.4975\n",
      "Epoch 16/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7403 - accuracy: 0.5174\n",
      "Epoch 17/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7114 - accuracy: 0.5423\n",
      "Epoch 18/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7310 - accuracy: 0.5025\n",
      "Epoch 19/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6979 - accuracy: 0.5174\n",
      "Epoch 20/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7119 - accuracy: 0.4627\n",
      "Epoch 21/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7017 - accuracy: 0.5423\n",
      "Epoch 22/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7079 - accuracy: 0.4826\n",
      "Epoch 23/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7081 - accuracy: 0.5473\n",
      "Epoch 24/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7092 - accuracy: 0.5373\n",
      "Epoch 25/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7109 - accuracy: 0.4876\n",
      "Epoch 26/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7388 - accuracy: 0.5174\n",
      "Epoch 27/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6979 - accuracy: 0.5672\n",
      "Epoch 28/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7484 - accuracy: 0.5075\n",
      "Epoch 29/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.5174\n",
      "Epoch 30/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.5224\n",
      "Epoch 31/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7281 - accuracy: 0.4726\n",
      "Epoch 32/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7913 - accuracy: 0.4975\n",
      "Epoch 33/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7573 - accuracy: 0.4627\n",
      "Epoch 34/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7025 - accuracy: 0.5174\n",
      "Epoch 35/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7790 - accuracy: 0.4378\n",
      "Epoch 36/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7299 - accuracy: 0.5124\n",
      "Epoch 37/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7319 - accuracy: 0.5025\n",
      "Epoch 38/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7024 - accuracy: 0.4876\n",
      "Epoch 39/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7112 - accuracy: 0.5224\n",
      "Epoch 40/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7098 - accuracy: 0.4975\n",
      "Epoch 41/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.5323\n",
      "Epoch 42/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8023 - accuracy: 0.5124\n",
      "Epoch 43/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8180 - accuracy: 0.4677\n",
      "Epoch 44/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7066 - accuracy: 0.5323\n",
      "Epoch 45/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7326 - accuracy: 0.4925\n",
      "Epoch 46/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7137 - accuracy: 0.5224\n",
      "Epoch 47/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7315 - accuracy: 0.5124\n",
      "Epoch 48/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8128 - accuracy: 0.4975\n",
      "Epoch 49/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8604 - accuracy: 0.4726\n",
      "Epoch 50/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.5522\n",
      "Epoch 51/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7098 - accuracy: 0.5124\n",
      "Epoch 52/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7561 - accuracy: 0.5025\n",
      "Epoch 53/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7007 - accuracy: 0.5075\n",
      "Epoch 54/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7120 - accuracy: 0.5224\n",
      "Epoch 55/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.5473\n",
      "Epoch 56/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7261 - accuracy: 0.5025\n",
      "Epoch 57/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7477 - accuracy: 0.4826\n",
      "Epoch 58/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.5473\n",
      "Epoch 59/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7154 - accuracy: 0.5075\n",
      "Epoch 60/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7253 - accuracy: 0.4776\n",
      "Epoch 61/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7107 - accuracy: 0.5473\n",
      "Epoch 62/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7251 - accuracy: 0.5174\n",
      "Epoch 63/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.5174\n",
      "Epoch 64/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.5124\n",
      "Epoch 65/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.5473\n",
      "Epoch 66/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7235 - accuracy: 0.4577\n",
      "Epoch 67/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7416 - accuracy: 0.4726\n",
      "Epoch 68/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7325 - accuracy: 0.4677\n",
      "Epoch 69/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7500 - accuracy: 0.4876\n",
      "Epoch 70/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7180 - accuracy: 0.5274\n",
      "Epoch 71/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7112 - accuracy: 0.5473\n",
      "Epoch 72/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7279 - accuracy: 0.5224\n",
      "Epoch 73/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7217 - accuracy: 0.5224\n",
      "Epoch 74/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.5274\n",
      "Epoch 75/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8126 - accuracy: 0.4428\n",
      "Epoch 76/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.8216 - accuracy: 0.4876\n",
      "Epoch 77/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7533 - accuracy: 0.5025\n",
      "Epoch 78/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7909 - accuracy: 0.5373\n",
      "Epoch 79/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7076 - accuracy: 0.5124\n",
      "Epoch 80/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7329 - accuracy: 0.4876\n",
      "Epoch 81/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7095 - accuracy: 0.5323\n",
      "Epoch 82/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.5373\n",
      "Epoch 83/523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7111 - accuracy: 0.5274\n",
      "Epoch 84/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7637 - accuracy: 0.5025\n",
      "Epoch 85/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.4876\n",
      "Epoch 86/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7435 - accuracy: 0.4925\n",
      "Epoch 87/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7119 - accuracy: 0.5025\n",
      "Epoch 88/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7440 - accuracy: 0.4876\n",
      "Epoch 89/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.5274\n",
      "Epoch 90/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7924 - accuracy: 0.4677\n",
      "Epoch 91/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7447 - accuracy: 0.4975\n",
      "Epoch 92/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6987 - accuracy: 0.5522\n",
      "Epoch 93/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7686 - accuracy: 0.5025\n",
      "Epoch 94/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8460 - accuracy: 0.4975\n",
      "Epoch 95/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6979 - accuracy: 0.5025\n",
      "Epoch 96/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7012 - accuracy: 0.5174\n",
      "Epoch 97/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7365 - accuracy: 0.5224\n",
      "Epoch 98/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6998 - accuracy: 0.5522\n",
      "Epoch 99/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.5721\n",
      "Epoch 100/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7383 - accuracy: 0.5075\n",
      "Epoch 101/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6996 - accuracy: 0.5423\n",
      "Epoch 102/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7278 - accuracy: 0.4925\n",
      "Epoch 103/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7146 - accuracy: 0.5224\n",
      "Epoch 104/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7178 - accuracy: 0.5075\n",
      "Epoch 105/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7333 - accuracy: 0.4826\n",
      "Epoch 106/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7605 - accuracy: 0.4627\n",
      "Epoch 107/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6996 - accuracy: 0.4826\n",
      "Epoch 108/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6932 - accuracy: 0.5672\n",
      "Epoch 109/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7155 - accuracy: 0.4478\n",
      "Epoch 110/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7056 - accuracy: 0.5075\n",
      "Epoch 111/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7601 - accuracy: 0.4527\n",
      "Epoch 112/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6984 - accuracy: 0.5473\n",
      "Epoch 113/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7268 - accuracy: 0.5124\n",
      "Epoch 114/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7213 - accuracy: 0.5423\n",
      "Epoch 115/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7120 - accuracy: 0.4925\n",
      "Epoch 116/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7216 - accuracy: 0.4677\n",
      "Epoch 117/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7012 - accuracy: 0.5075\n",
      "Epoch 118/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.5274\n",
      "Epoch 119/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7321 - accuracy: 0.5672\n",
      "Epoch 120/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.4925\n",
      "Epoch 121/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7525 - accuracy: 0.5025\n",
      "Epoch 122/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7073 - accuracy: 0.4876\n",
      "Epoch 123/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7483 - accuracy: 0.4378\n",
      "Epoch 124/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7172 - accuracy: 0.5522\n",
      "Epoch 125/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.5224\n",
      "Epoch 126/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7483 - accuracy: 0.4925\n",
      "Epoch 127/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7081 - accuracy: 0.4975\n",
      "Epoch 128/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.5025\n",
      "Epoch 129/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.5274\n",
      "Epoch 130/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6965 - accuracy: 0.5423\n",
      "Epoch 131/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7622 - accuracy: 0.5124\n",
      "Epoch 132/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7321 - accuracy: 0.5174\n",
      "Epoch 133/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7325 - accuracy: 0.5075\n",
      "Epoch 134/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.5174\n",
      "Epoch 135/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7278 - accuracy: 0.5025\n",
      "Epoch 136/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.5224\n",
      "Epoch 137/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7275 - accuracy: 0.5323\n",
      "Epoch 138/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7731 - accuracy: 0.4975\n",
      "Epoch 139/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6967 - accuracy: 0.5274\n",
      "Epoch 140/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7105 - accuracy: 0.5572\n",
      "Epoch 141/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6986 - accuracy: 0.5473\n",
      "Epoch 142/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 0.4975\n",
      "Epoch 143/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7181 - accuracy: 0.4925\n",
      "Epoch 144/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7146 - accuracy: 0.5025\n",
      "Epoch 145/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7140 - accuracy: 0.4975\n",
      "Epoch 146/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7464 - accuracy: 0.4876\n",
      "Epoch 147/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7478 - accuracy: 0.5323\n",
      "Epoch 148/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7069 - accuracy: 0.4726\n",
      "Epoch 149/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7163 - accuracy: 0.4925\n",
      "Epoch 150/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7308 - accuracy: 0.5224\n",
      "Epoch 151/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7888 - accuracy: 0.4975\n",
      "Epoch 152/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7862 - accuracy: 0.5473\n",
      "Epoch 153/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.4925\n",
      "Epoch 154/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7410 - accuracy: 0.4975\n",
      "Epoch 155/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7032 - accuracy: 0.4826\n",
      "Epoch 156/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7244 - accuracy: 0.4726\n",
      "Epoch 157/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7518 - accuracy: 0.5423\n",
      "Epoch 158/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7868 - accuracy: 0.4776\n",
      "Epoch 159/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7548 - accuracy: 0.5572\n",
      "Epoch 160/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7344 - accuracy: 0.5025\n",
      "Epoch 161/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7101 - accuracy: 0.5423\n",
      "Epoch 162/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7112 - accuracy: 0.4975\n",
      "Epoch 163/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7003 - accuracy: 0.5174\n",
      "Epoch 164/523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7050 - accuracy: 0.5124\n",
      "Epoch 165/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7024 - accuracy: 0.5224\n",
      "Epoch 166/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7280 - accuracy: 0.5473\n",
      "Epoch 167/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5124\n",
      "Epoch 168/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7494 - accuracy: 0.5274\n",
      "Epoch 169/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7161 - accuracy: 0.5075\n",
      "Epoch 170/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7238 - accuracy: 0.4925\n",
      "Epoch 171/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7045 - accuracy: 0.5124\n",
      "Epoch 172/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7246 - accuracy: 0.5075\n",
      "Epoch 173/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7268 - accuracy: 0.5025\n",
      "Epoch 174/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7165 - accuracy: 0.4328\n",
      "Epoch 175/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7840 - accuracy: 0.4975\n",
      "Epoch 176/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7980 - accuracy: 0.5174\n",
      "Epoch 177/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7826 - accuracy: 0.5373\n",
      "Epoch 178/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7674 - accuracy: 0.4677\n",
      "Epoch 179/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7193 - accuracy: 0.5124\n",
      "Epoch 180/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6941 - accuracy: 0.5224\n",
      "Epoch 181/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7203 - accuracy: 0.5124\n",
      "Epoch 182/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7052 - accuracy: 0.4876\n",
      "Epoch 183/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7314 - accuracy: 0.4627\n",
      "Epoch 184/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7476 - accuracy: 0.4726\n",
      "Epoch 185/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.5572\n",
      "Epoch 186/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7369 - accuracy: 0.5075\n",
      "Epoch 187/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7107 - accuracy: 0.4776\n",
      "Epoch 188/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7124 - accuracy: 0.5274\n",
      "Epoch 189/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7925 - accuracy: 0.5075\n",
      "Epoch 190/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7641 - accuracy: 0.5174\n",
      "Epoch 191/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7145 - accuracy: 0.4677\n",
      "Epoch 192/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7140 - accuracy: 0.5124\n",
      "Epoch 193/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7165 - accuracy: 0.5274\n",
      "Epoch 194/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7363 - accuracy: 0.4627\n",
      "Epoch 195/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.5721\n",
      "Epoch 196/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7057 - accuracy: 0.4826\n",
      "Epoch 197/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7231 - accuracy: 0.4876\n",
      "Epoch 198/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.5473\n",
      "Epoch 199/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7338 - accuracy: 0.4975\n",
      "Epoch 200/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7336 - accuracy: 0.5323\n",
      "Epoch 201/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.5423\n",
      "Epoch 202/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7131 - accuracy: 0.5323\n",
      "Epoch 203/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.5224\n",
      "Epoch 204/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7265 - accuracy: 0.5174\n",
      "Epoch 205/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7014 - accuracy: 0.4677\n",
      "Epoch 206/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7255 - accuracy: 0.5572\n",
      "Epoch 207/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7241 - accuracy: 0.5124\n",
      "Epoch 208/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7206 - accuracy: 0.4627\n",
      "Epoch 209/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7078 - accuracy: 0.5771\n",
      "Epoch 210/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8360 - accuracy: 0.4876\n",
      "Epoch 211/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7269 - accuracy: 0.5323\n",
      "Epoch 212/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7500 - accuracy: 0.5224\n",
      "Epoch 213/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8006 - accuracy: 0.4776\n",
      "Epoch 214/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7301 - accuracy: 0.4577\n",
      "Epoch 215/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7556 - accuracy: 0.5025\n",
      "Epoch 216/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7382 - accuracy: 0.5025\n",
      "Epoch 217/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7157 - accuracy: 0.5075\n",
      "Epoch 218/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.5025\n",
      "Epoch 219/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7202 - accuracy: 0.5473\n",
      "Epoch 220/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7091 - accuracy: 0.5224\n",
      "Epoch 221/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7106 - accuracy: 0.4726\n",
      "Epoch 222/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7245 - accuracy: 0.5025\n",
      "Epoch 223/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7521 - accuracy: 0.5323\n",
      "Epoch 224/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5423\n",
      "Epoch 225/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7177 - accuracy: 0.4876\n",
      "Epoch 226/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7251 - accuracy: 0.4776\n",
      "Epoch 227/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6978 - accuracy: 0.4876\n",
      "Epoch 228/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.5622\n",
      "Epoch 229/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.5174\n",
      "Epoch 230/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7126 - accuracy: 0.4527\n",
      "Epoch 231/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7291 - accuracy: 0.4826\n",
      "Epoch 232/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7132 - accuracy: 0.5423\n",
      "Epoch 233/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7525 - accuracy: 0.4428\n",
      "Epoch 234/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8196 - accuracy: 0.4577\n",
      "Epoch 235/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6982 - accuracy: 0.5224\n",
      "Epoch 236/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7142 - accuracy: 0.5274\n",
      "Epoch 237/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6989 - accuracy: 0.5373\n",
      "Epoch 238/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7033 - accuracy: 0.5473\n",
      "Epoch 239/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7092 - accuracy: 0.4975\n",
      "Epoch 240/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7779 - accuracy: 0.5373\n",
      "Epoch 241/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7783 - accuracy: 0.5174\n",
      "Epoch 242/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7049 - accuracy: 0.5373\n",
      "Epoch 243/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7083 - accuracy: 0.5572\n",
      "Epoch 244/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.5224\n",
      "Epoch 245/523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7283 - accuracy: 0.4428\n",
      "Epoch 246/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7228 - accuracy: 0.5473\n",
      "Epoch 247/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7031 - accuracy: 0.5373\n",
      "Epoch 248/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7034 - accuracy: 0.5572\n",
      "Epoch 249/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.5274\n",
      "Epoch 250/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6975 - accuracy: 0.5124\n",
      "Epoch 251/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.5522\n",
      "Epoch 252/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7095 - accuracy: 0.5224\n",
      "Epoch 253/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7415 - accuracy: 0.5174\n",
      "Epoch 254/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7939 - accuracy: 0.4527\n",
      "Epoch 255/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7088 - accuracy: 0.5124\n",
      "Epoch 256/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6972 - accuracy: 0.5373\n",
      "Epoch 257/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7123 - accuracy: 0.5323\n",
      "Epoch 258/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7070 - accuracy: 0.5323\n",
      "Epoch 259/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.5224\n",
      "Epoch 260/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7260 - accuracy: 0.4876\n",
      "Epoch 261/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7164 - accuracy: 0.4876\n",
      "Epoch 262/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7193 - accuracy: 0.4726\n",
      "Epoch 263/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7337 - accuracy: 0.5025\n",
      "Epoch 264/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7038 - accuracy: 0.5920\n",
      "Epoch 265/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7636 - accuracy: 0.4378\n",
      "Epoch 266/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7465 - accuracy: 0.5323\n",
      "Epoch 267/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7272 - accuracy: 0.4726\n",
      "Epoch 268/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6949 - accuracy: 0.5174\n",
      "Epoch 269/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7111 - accuracy: 0.5075\n",
      "Epoch 270/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7565 - accuracy: 0.4577\n",
      "Epoch 271/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7892 - accuracy: 0.5274\n",
      "Epoch 272/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7354 - accuracy: 0.5274\n",
      "Epoch 273/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7037 - accuracy: 0.5522\n",
      "Epoch 274/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7101 - accuracy: 0.4975\n",
      "Epoch 275/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7692 - accuracy: 0.4279\n",
      "Epoch 276/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7080 - accuracy: 0.4925\n",
      "Epoch 277/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7204 - accuracy: 0.5274\n",
      "Epoch 278/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 0.4975\n",
      "Epoch 279/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7022 - accuracy: 0.5274\n",
      "Epoch 280/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7242 - accuracy: 0.5025\n",
      "Epoch 281/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7204 - accuracy: 0.4577\n",
      "Epoch 282/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7054 - accuracy: 0.4776\n",
      "Epoch 283/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7576 - accuracy: 0.5124\n",
      "Epoch 284/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7215 - accuracy: 0.4776\n",
      "Epoch 285/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.5174\n",
      "Epoch 286/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6951 - accuracy: 0.5224\n",
      "Epoch 287/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7850 - accuracy: 0.4577\n",
      "Epoch 288/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8007 - accuracy: 0.4726\n",
      "Epoch 289/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7619 - accuracy: 0.4677\n",
      "Epoch 290/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7904 - accuracy: 0.4478\n",
      "Epoch 291/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8086 - accuracy: 0.4577\n",
      "Epoch 292/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7810 - accuracy: 0.4876\n",
      "Epoch 293/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7027 - accuracy: 0.5025\n",
      "Epoch 294/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7077 - accuracy: 0.4925\n",
      "Epoch 295/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5323\n",
      "Epoch 296/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7096 - accuracy: 0.5025\n",
      "Epoch 297/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7113 - accuracy: 0.5274\n",
      "Epoch 298/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7406 - accuracy: 0.4826\n",
      "Epoch 299/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7394 - accuracy: 0.5224\n",
      "Epoch 300/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6874 - accuracy: 0.5522\n",
      "Epoch 301/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6992 - accuracy: 0.4975\n",
      "Epoch 302/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7821 - accuracy: 0.4428\n",
      "Epoch 303/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7138 - accuracy: 0.5075\n",
      "Epoch 304/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.5373\n",
      "Epoch 305/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7415 - accuracy: 0.5572\n",
      "Epoch 306/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7160 - accuracy: 0.4925\n",
      "Epoch 307/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7296 - accuracy: 0.5174\n",
      "Epoch 308/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7634 - accuracy: 0.4826\n",
      "Epoch 309/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.4776\n",
      "Epoch 310/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7027 - accuracy: 0.5522\n",
      "Epoch 311/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.4925\n",
      "Epoch 312/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7150 - accuracy: 0.5323\n",
      "Epoch 313/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7517 - accuracy: 0.4428\n",
      "Epoch 314/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7584 - accuracy: 0.4876\n",
      "Epoch 315/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7099 - accuracy: 0.4876\n",
      "Epoch 316/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.5323\n",
      "Epoch 317/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7071 - accuracy: 0.4826\n",
      "Epoch 318/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7028 - accuracy: 0.5075\n",
      "Epoch 319/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7080 - accuracy: 0.5124\n",
      "Epoch 320/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7096 - accuracy: 0.5174\n",
      "Epoch 321/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7109 - accuracy: 0.5025\n",
      "Epoch 322/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7143 - accuracy: 0.5075\n",
      "Epoch 323/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7053 - accuracy: 0.4876\n",
      "Epoch 324/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6960 - accuracy: 0.5473\n",
      "Epoch 325/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7342 - accuracy: 0.5025\n",
      "Epoch 326/523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.5224\n",
      "Epoch 327/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7186 - accuracy: 0.5224\n",
      "Epoch 328/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.5473\n",
      "Epoch 329/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5473\n",
      "Epoch 330/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7445 - accuracy: 0.4876\n",
      "Epoch 331/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7079 - accuracy: 0.5274\n",
      "Epoch 332/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.5174\n",
      "Epoch 333/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7021 - accuracy: 0.5124\n",
      "Epoch 334/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7291 - accuracy: 0.4925\n",
      "Epoch 335/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7229 - accuracy: 0.5622\n",
      "Epoch 336/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7016 - accuracy: 0.5323\n",
      "Epoch 337/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.5224\n",
      "Epoch 338/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7139 - accuracy: 0.5174\n",
      "Epoch 339/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7189 - accuracy: 0.4577\n",
      "Epoch 340/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7406 - accuracy: 0.4925\n",
      "Epoch 341/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7045 - accuracy: 0.5224\n",
      "Epoch 342/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7210 - accuracy: 0.5174\n",
      "Epoch 343/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7066 - accuracy: 0.4975\n",
      "Epoch 344/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7286 - accuracy: 0.5473\n",
      "Epoch 345/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7412 - accuracy: 0.4478\n",
      "Epoch 346/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7017 - accuracy: 0.4876\n",
      "Epoch 347/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7386 - accuracy: 0.4527\n",
      "Epoch 348/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6988 - accuracy: 0.5373\n",
      "Epoch 349/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7046 - accuracy: 0.5423\n",
      "Epoch 350/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6984 - accuracy: 0.5224\n",
      "Epoch 351/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7173 - accuracy: 0.4876\n",
      "Epoch 352/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7170 - accuracy: 0.4478\n",
      "Epoch 353/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7120 - accuracy: 0.4726\n",
      "Epoch 354/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.5572\n",
      "Epoch 355/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7675 - accuracy: 0.4428\n",
      "Epoch 356/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7102 - accuracy: 0.5124\n",
      "Epoch 357/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7024 - accuracy: 0.4925\n",
      "Epoch 358/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7434 - accuracy: 0.5124\n",
      "Epoch 359/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7283 - accuracy: 0.4527\n",
      "Epoch 360/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7442 - accuracy: 0.5473\n",
      "Epoch 361/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7397 - accuracy: 0.4776\n",
      "Epoch 362/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6966 - accuracy: 0.5473\n",
      "Epoch 363/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7331 - accuracy: 0.5075\n",
      "Epoch 364/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7041 - accuracy: 0.5423\n",
      "Epoch 365/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7378 - accuracy: 0.4527\n",
      "Epoch 366/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7254 - accuracy: 0.5075\n",
      "Epoch 367/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6943 - accuracy: 0.5721\n",
      "Epoch 368/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7956 - accuracy: 0.4577\n",
      "Epoch 369/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7300 - accuracy: 0.5672\n",
      "Epoch 370/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7552 - accuracy: 0.4677\n",
      "Epoch 371/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7320 - accuracy: 0.5274\n",
      "Epoch 372/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.5075\n",
      "Epoch 373/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7453 - accuracy: 0.4776\n",
      "Epoch 374/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7433 - accuracy: 0.4826\n",
      "Epoch 375/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7124 - accuracy: 0.4925\n",
      "Epoch 376/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6968 - accuracy: 0.5025\n",
      "Epoch 377/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7064 - accuracy: 0.4826\n",
      "Epoch 378/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7251 - accuracy: 0.4428\n",
      "Epoch 379/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7278 - accuracy: 0.5025\n",
      "Epoch 380/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6990 - accuracy: 0.4975\n",
      "Epoch 381/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.5473\n",
      "Epoch 382/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7024 - accuracy: 0.5224\n",
      "Epoch 383/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7297 - accuracy: 0.4577\n",
      "Epoch 384/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7755 - accuracy: 0.5025\n",
      "Epoch 385/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7719 - accuracy: 0.4677\n",
      "Epoch 386/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7200 - accuracy: 0.4975\n",
      "Epoch 387/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7265 - accuracy: 0.5224\n",
      "Epoch 388/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7281 - accuracy: 0.5522\n",
      "Epoch 389/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7014 - accuracy: 0.5124\n",
      "Epoch 390/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7338 - accuracy: 0.4677\n",
      "Epoch 391/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7019 - accuracy: 0.5224\n",
      "Epoch 392/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7222 - accuracy: 0.4726\n",
      "Epoch 393/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7003 - accuracy: 0.5224\n",
      "Epoch 394/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7168 - accuracy: 0.4876\n",
      "Epoch 395/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7215 - accuracy: 0.5224\n",
      "Epoch 396/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7215 - accuracy: 0.5025\n",
      "Epoch 397/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.5423\n",
      "Epoch 398/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.5174\n",
      "Epoch 399/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7358 - accuracy: 0.4925\n",
      "Epoch 400/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7479 - accuracy: 0.5224\n",
      "Epoch 401/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7161 - accuracy: 0.4826\n",
      "Epoch 402/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7323 - accuracy: 0.5025\n",
      "Epoch 403/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7261 - accuracy: 0.4677\n",
      "Epoch 404/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7325 - accuracy: 0.5025\n",
      "Epoch 405/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7079 - accuracy: 0.5473\n",
      "Epoch 406/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7326 - accuracy: 0.4876\n",
      "Epoch 407/523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7093 - accuracy: 0.5025\n",
      "Epoch 408/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7345 - accuracy: 0.4925\n",
      "Epoch 409/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7265 - accuracy: 0.5323\n",
      "Epoch 410/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7106 - accuracy: 0.4776\n",
      "Epoch 411/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7060 - accuracy: 0.5423\n",
      "Epoch 412/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.5174\n",
      "Epoch 413/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7357 - accuracy: 0.4776\n",
      "Epoch 414/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7562 - accuracy: 0.4826\n",
      "Epoch 415/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.5124\n",
      "Epoch 416/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7089 - accuracy: 0.5075\n",
      "Epoch 417/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5274\n",
      "Epoch 418/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7047 - accuracy: 0.5174\n",
      "Epoch 419/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7023 - accuracy: 0.5572\n",
      "Epoch 420/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7180 - accuracy: 0.4925\n",
      "Epoch 421/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7170 - accuracy: 0.5075\n",
      "Epoch 422/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7032 - accuracy: 0.5174\n",
      "Epoch 423/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7098 - accuracy: 0.4975\n",
      "Epoch 424/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.5522\n",
      "Epoch 425/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8444 - accuracy: 0.4826\n",
      "Epoch 426/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7735 - accuracy: 0.5473\n",
      "Epoch 427/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7313 - accuracy: 0.5274\n",
      "Epoch 428/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7433 - accuracy: 0.5075\n",
      "Epoch 429/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7711 - accuracy: 0.5274\n",
      "Epoch 430/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.5025\n",
      "Epoch 431/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7609 - accuracy: 0.4328\n",
      "Epoch 432/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7055 - accuracy: 0.5721\n",
      "Epoch 433/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7195 - accuracy: 0.4726\n",
      "Epoch 434/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7309 - accuracy: 0.5174\n",
      "Epoch 435/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7353 - accuracy: 0.5224\n",
      "Epoch 436/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7391 - accuracy: 0.4726\n",
      "Epoch 437/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6986 - accuracy: 0.5473\n",
      "Epoch 438/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7267 - accuracy: 0.5124\n",
      "Epoch 439/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7147 - accuracy: 0.5721\n",
      "Epoch 440/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7656 - accuracy: 0.5075\n",
      "Epoch 441/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7389 - accuracy: 0.4826\n",
      "Epoch 442/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7027 - accuracy: 0.4925\n",
      "Epoch 443/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7421 - accuracy: 0.4776\n",
      "Epoch 444/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6983 - accuracy: 0.4776\n",
      "Epoch 445/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 0.5622\n",
      "Epoch 446/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7108 - accuracy: 0.5224\n",
      "Epoch 447/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7549 - accuracy: 0.4378\n",
      "Epoch 448/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7022 - accuracy: 0.4776\n",
      "Epoch 449/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7041 - accuracy: 0.5373\n",
      "Epoch 450/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7248 - accuracy: 0.5323\n",
      "Epoch 451/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7010 - accuracy: 0.5323\n",
      "Epoch 452/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6988 - accuracy: 0.5224\n",
      "Epoch 453/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7048 - accuracy: 0.5124\n",
      "Epoch 454/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5075\n",
      "Epoch 455/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7381 - accuracy: 0.4876\n",
      "Epoch 456/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.5323\n",
      "Epoch 457/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7095 - accuracy: 0.5174\n",
      "Epoch 458/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7080 - accuracy: 0.5274\n",
      "Epoch 459/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 0.5323\n",
      "Epoch 460/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7608 - accuracy: 0.5075\n",
      "Epoch 461/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8100 - accuracy: 0.4826\n",
      "Epoch 462/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7664 - accuracy: 0.5423\n",
      "Epoch 463/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7191 - accuracy: 0.4975\n",
      "Epoch 464/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7115 - accuracy: 0.4726\n",
      "Epoch 465/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7367 - accuracy: 0.4776\n",
      "Epoch 466/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6978 - accuracy: 0.5473\n",
      "Epoch 467/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7032 - accuracy: 0.5174\n",
      "Epoch 468/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7198 - accuracy: 0.5025\n",
      "Epoch 469/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7155 - accuracy: 0.5075\n",
      "Epoch 470/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.4876\n",
      "Epoch 471/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7050 - accuracy: 0.5522\n",
      "Epoch 472/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 0.4527\n",
      "Epoch 473/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7386 - accuracy: 0.4876\n",
      "Epoch 474/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7547 - accuracy: 0.4229\n",
      "Epoch 475/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7001 - accuracy: 0.4876\n",
      "Epoch 476/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6990 - accuracy: 0.4975\n",
      "Epoch 477/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7164 - accuracy: 0.5423\n",
      "Epoch 478/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7069 - accuracy: 0.5124\n",
      "Epoch 479/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7185 - accuracy: 0.5124\n",
      "Epoch 480/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7230 - accuracy: 0.5075\n",
      "Epoch 481/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.5423\n",
      "Epoch 482/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7388 - accuracy: 0.5174\n",
      "Epoch 483/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7534 - accuracy: 0.4826\n",
      "Epoch 484/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7065 - accuracy: 0.5224\n",
      "Epoch 485/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7618 - accuracy: 0.4876\n",
      "Epoch 486/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7200 - accuracy: 0.5323\n",
      "Epoch 487/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7142 - accuracy: 0.4826\n",
      "Epoch 488/523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6983 - accuracy: 0.4925\n",
      "Epoch 489/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7460 - accuracy: 0.4527\n",
      "Epoch 490/523\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7372 - accuracy: 0.5622\n",
      "Epoch 491/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6988 - accuracy: 0.5124\n",
      "Epoch 492/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7777 - accuracy: 0.4975\n",
      "Epoch 493/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7388 - accuracy: 0.4677\n",
      "Epoch 494/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7411 - accuracy: 0.4975\n",
      "Epoch 495/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7315 - accuracy: 0.4925\n",
      "Epoch 496/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7094 - accuracy: 0.5025\n",
      "Epoch 497/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7455 - accuracy: 0.5622\n",
      "Epoch 498/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7031 - accuracy: 0.4925\n",
      "Epoch 499/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.5075\n",
      "Epoch 500/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7718 - accuracy: 0.5075\n",
      "Epoch 501/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7276 - accuracy: 0.4776\n",
      "Epoch 502/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7209 - accuracy: 0.4527\n",
      "Epoch 503/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.5124\n",
      "Epoch 504/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7718 - accuracy: 0.4776\n",
      "Epoch 505/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7035 - accuracy: 0.5572\n",
      "Epoch 506/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7014 - accuracy: 0.5473\n",
      "Epoch 507/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7410 - accuracy: 0.4876\n",
      "Epoch 508/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.4975\n",
      "Epoch 509/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7590 - accuracy: 0.5075\n",
      "Epoch 510/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7340 - accuracy: 0.4726\n",
      "Epoch 511/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7164 - accuracy: 0.5323\n",
      "Epoch 512/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7111 - accuracy: 0.4577\n",
      "Epoch 513/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7084 - accuracy: 0.5075\n",
      "Epoch 514/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.6981 - accuracy: 0.5124\n",
      "Epoch 515/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7193 - accuracy: 0.5224\n",
      "Epoch 516/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7198 - accuracy: 0.5124\n",
      "Epoch 517/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7092 - accuracy: 0.5871\n",
      "Epoch 518/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.8410 - accuracy: 0.5373\n",
      "Epoch 519/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7300 - accuracy: 0.5423\n",
      "Epoch 520/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7115 - accuracy: 0.5224\n",
      "Epoch 521/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7127 - accuracy: 0.5075\n",
      "Epoch 522/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7203 - accuracy: 0.5871\n",
      "Epoch 523/523\n",
      "21/21 [==============================] - 0s 1ms/step - loss: 0.7281 - accuracy: 0.5323\n"
     ]
    }
   ],
   "source": [
    "# Fit the data\n",
    "\n",
    "history = model.fit(\n",
    "  X_train,\n",
    "  to_categorical(y_train), \n",
    "  epochs=523, \n",
    "  batch_size=10, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7719 - accuracy: 0.5174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7719042301177979, 0.5174129605293274]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "model.evaluate(\n",
    "  X_test,\n",
    "  to_categorical(y_test)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure if I didn't understood well or I'm not aplying my model as I configured on the playground website.\n",
      "I think that I'm configuring one neural network with:\n",
      "- 6 inputs (features)\n",
      "- 1 layer with 7 neurons\n",
      "- 1 output with 2 neurons (because in our dataset the target only have 2 options)\n",
      "I also split the dataset at 50% and set the batch size to 10 (I didn't knew to add noise, I think that should to add to the dataset).\n",
      "I used activation = Sigmoid in every layer (because there is only one option to choose in the website) and tried 2 optimizers with the learning rate of 0.1\n",
      "\n",
      "I tried diferent values of the hyperparameters and couldn't improve it (I tried to scale the features, add layers, neurons, diferent activators, more epochs)\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"I'm not sure if I didn't understood well or I'm not aplying my model as I configured on the playground website.\n",
    "I think that I'm configuring one neural network with:\n",
    "- 6 inputs (features)\n",
    "- 1 layer with 7 neurons\n",
    "- 1 output with 2 neurons (because in our dataset the target only have 2 options)\n",
    "I also split the dataset at 50% and set the batch size to 10 (I didn't knew to add noise, I think that should to add to the dataset).\n",
    "I used activation = Sigmoid in every layer (because there is only one option to choose in the website) and tried 2 optimizers with the learning rate of 0.1\n",
    "\n",
    "I tried diferent values of the hyperparameters and couldn't improve it (I tried to scale the features, add layers, neurons, diferent activators, more epochs)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
